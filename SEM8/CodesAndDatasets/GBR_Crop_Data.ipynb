{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii2yPnWmnDqN",
        "outputId": "7b1dcd94-4e55-44b2-97f1-c43a1e89ba1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MCmntA3BOquC7BWxLcYDItohDgTPRKx8\n",
            "To: /content/Crop_Data_Final.csv\n",
            "100%|██████████| 214k/214k [00:00<00:00, 4.22MB/s]\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "file_id = '1MCmntA3BOquC7BWxLcYDItohDgTPRKx8'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output = 'Crop_Data_Final.csv'\n",
        "gdown.download(url, output, quiet=False)\n",
        "df = pd.read_csv('Crop_Data_Final.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpOCPx49pO-f",
        "outputId": "bd2c3914-0aaf-42ed-f36b-149e987db09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Year', 'Dist Name', 'RICE AREA (1000 ha)',\n",
              "       'RICE PRODUCTION (1000 tons)', 'RICE YIELD (Kg per ha)',\n",
              "       'WHEAT AREA (1000 ha)', 'WHEAT PRODUCTION (1000 tons)',\n",
              "       'WHEAT YIELD (Kg per ha)', 'SORGHUM AREA (1000 ha)',\n",
              "       'SORGHUM PRODUCTION (1000 tons)', 'SORGHUM YIELD (Kg per ha)',\n",
              "       'PEARL MILLET AREA (1000 ha)', 'PEARL MILLET PRODUCTION (1000 tons)',\n",
              "       'PEARL MILLET YIELD (Kg per ha)', 'MAIZE AREA (1000 ha)',\n",
              "       'MAIZE PRODUCTION (1000 tons)', 'MAIZE YIELD (Kg per ha)',\n",
              "       'CHICKPEA AREA (1000 ha)', 'CHICKPEA PRODUCTION (1000 tons)',\n",
              "       'CHICKPEA YIELD (Kg per ha)', 'PIGEONPEA AREA (1000 ha)',\n",
              "       'PIGEONPEA PRODUCTION (1000 tons)', 'PIGEONPEA YIELD (Kg per ha)',\n",
              "       'MINOR PULSES AREA (1000 ha)', 'MINOR PULSES PRODUCTION (1000 tons)',\n",
              "       'MINOR PULSES YIELD (Kg per ha)', 'GROUNDNUT AREA (1000 ha)',\n",
              "       'GROUNDNUT PRODUCTION (1000 tons)', 'GROUNDNUT YIELD (Kg per ha)',\n",
              "       'SESAMUM AREA (1000 ha)', 'SESAMUM PRODUCTION (1000 tons)',\n",
              "       'SESAMUM YIELD (Kg per ha)', 'OILSEEDS AREA (1000 ha)',\n",
              "       'OILSEEDS PRODUCTION (1000 tons)', 'OILSEEDS YIELD (Kg per ha)',\n",
              "       'SUGARCANE AREA (1000 ha)', 'SUGARCANE PRODUCTION (1000 tons)',\n",
              "       'SUGARCANE YIELD (Kg per ha)', 'COTTON AREA (1000 ha)',\n",
              "       'COTTON PRODUCTION (1000 tons)', 'COTTON YIELD (Kg per ha)',\n",
              "       'FRUITS AND VEGETABLES AREA (1000 ha)',\n",
              "       'NITROGEN SHARE IN NPK (Percent)', 'NITROGEN PER HA OF NCA (Kg per ha)',\n",
              "       'NITROGEN PER HA OF GCA (Kg per ha)', 'PHOSPHATE CONSUMPTION (tons)',\n",
              "       'PHOSPHATE SHARE IN NPK (Percent)',\n",
              "       'PHOSPHATE PER HA OF NCA (Kg per ha)',\n",
              "       'PHOSPHATE PER HA OF GCA (Kg per ha)', 'POTASH CONSUMPTION (tons)',\n",
              "       'POTASH SHARE IN NPK (Percent)', 'POTASH PER HA OF NCA (Kg per ha)',\n",
              "       'POTASH PER HA OF GCA (Kg per ha)', 'Min Temp (Centigrate)',\n",
              "       'Max Temp (Centigrate)', 'Precipitation (mm)', 'Irrigated Area',\n",
              "       'Annual Rainfall'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Crop_Data_Final.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Future years to forecast\n",
        "future_years = list(range(2017, 2024)) + [2025, 2030, 2035, 2040, 2045, 2050]\n",
        "\n",
        "# Districts to process\n",
        "districts = data['Dist Name'].unique()\n",
        "\n",
        "# Crop-related target columns\n",
        "crop_columns = {\n",
        "    'Rice': ['RICE AREA (1000 ha)', 'RICE PRODUCTION (1000 tons)', 'RICE YIELD (Kg per ha)'],\n",
        "    'Wheat': ['WHEAT AREA (1000 ha)', 'WHEAT PRODUCTION (1000 tons)', 'WHEAT YIELD (Kg per ha)'],\n",
        "    'Sorghum': ['SORGHUM AREA (1000 ha)', 'SORGHUM PRODUCTION (1000 tons)', 'SORGHUM YIELD (Kg per ha)'],\n",
        "    'Pearl Millet': ['PEARL MILLET AREA (1000 ha)', 'PEARL MILLET PRODUCTION (1000 tons)', 'PEARL MILLET YIELD (Kg per ha)'],\n",
        "    'Maize': ['MAIZE AREA (1000 ha)', 'MAIZE PRODUCTION (1000 tons)', 'MAIZE YIELD (Kg per ha)'],\n",
        "    'Chickpea': ['CHICKPEA AREA (1000 ha)', 'CHICKPEA PRODUCTION (1000 tons)', 'CHICKPEA YIELD (Kg per ha)'],\n",
        "    'Pigeonpea': ['PIGEONPEA AREA (1000 ha)', 'PIGEONPEA PRODUCTION (1000 tons)', 'PIGEONPEA YIELD (Kg per ha)'],\n",
        "    'Minor Pulses': ['MINOR PULSES AREA (1000 ha)', 'MINOR PULSES PRODUCTION (1000 tons)', 'MINOR PULSES YIELD (Kg per ha)'],\n",
        "    'Groundnut': ['GROUNDNUT AREA (1000 ha)', 'GROUNDNUT PRODUCTION (1000 tons)', 'GROUNDNUT YIELD (Kg per ha)'],\n",
        "    'Sesamum': ['SESAMUM AREA (1000 ha)', 'SESAMUM PRODUCTION (1000 tons)', 'SESAMUM YIELD (Kg per ha)'],\n",
        "    'Oilseeds': ['OILSEEDS AREA (1000 ha)', 'OILSEEDS PRODUCTION (1000 tons)', 'OILSEEDS YIELD (Kg per ha)'],\n",
        "    'Sugarcane': ['SUGARCANE AREA (1000 ha)', 'SUGARCANE PRODUCTION (1000 tons)', 'SUGARCANE YIELD (Kg per ha)'],\n",
        "    'Cotton': ['COTTON AREA (1000 ha)', 'COTTON PRODUCTION (1000 tons)', 'COTTON YIELD (Kg per ha)'],\n",
        "    'Fruits and Vegetables': ['FRUITS AND VEGETABLES AREA (1000 ha)'],\n",
        "    'Fertilizers': ['NITROGEN SHARE IN NPK (Percent)', 'PHOSPHATE SHARE IN NPK (Percent)', 'POTASH SHARE IN NPK (Percent)'],\n",
        "    'Soil Nutrients': ['NITROGEN PER HA OF NCA (Kg per ha)', 'NITROGEN PER HA OF GCA (Kg per ha)',\n",
        "                       'PHOSPHATE PER HA OF NCA (Kg per ha)', 'PHOSPHATE PER HA OF GCA (Kg per ha)',\n",
        "                       'POTASH PER HA OF NCA (Kg per ha)', 'POTASH PER HA OF GCA (Kg per ha)'],\n",
        "    'Weather': ['Min Temp (Centigrate)', 'Max Temp (Centigrate)', 'Precipitation (mm)', 'Irrigated Area', 'Annual Rainfall']\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning grid\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 3],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Function to calculate additional evaluation metrics (MAE, MAPE, RMSE)\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # MAPE in percentage\n",
        "    rmse = np.sqrt(mse)\n",
        "    return mse, r2, mae, mape, rmse\n",
        "\n",
        "# Function to process each district and target column\n",
        "def process_district(district):\n",
        "    results = {'fine_tuning': [], 'forecasting': []}\n",
        "    district_data = data[data['Dist Name'] == district]\n",
        "\n",
        "    # Iterate over each crop\n",
        "    for crop, columns in crop_columns.items():\n",
        "        # Only focus on the columns for the current crop\n",
        "        X = district_data.drop(columns=['Year', 'Dist Name'] + [col for col in data.columns if col not in columns], errors='ignore')\n",
        "\n",
        "        for target_column in columns:\n",
        "            y = district_data[target_column]\n",
        "\n",
        "            # Skip columns with insufficient data\n",
        "            if len(y) < 5:\n",
        "                continue\n",
        "\n",
        "            # Split the data into train and test sets (80:20 split)\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Randomized search for hyperparameter tuning\n",
        "            gbr = GradientBoostingRegressor(random_state=42)\n",
        "            random_search = RandomizedSearchCV(\n",
        "                estimator=gbr,\n",
        "                param_distributions=param_distributions,\n",
        "                n_iter=10,  # Reducing iterations for speed\n",
        "                cv=2,\n",
        "                scoring='neg_mean_squared_error',\n",
        "                n_jobs=-1,\n",
        "                verbose=0\n",
        "            )\n",
        "            random_search.fit(X_train, y_train)\n",
        "\n",
        "            # Best parameters and model\n",
        "            best_params = random_search.best_params_\n",
        "            best_model = random_search.best_estimator_\n",
        "\n",
        "            # Evaluate the model on test data\n",
        "            y_pred = best_model.predict(X_test)\n",
        "            mse, r2, mae, mape, rmse = calculate_metrics(y_test, y_pred)\n",
        "\n",
        "            # Store fine-tuning results\n",
        "            results['fine_tuning'].append({\n",
        "                'District': district,\n",
        "                'Crop': crop,\n",
        "                'Target Column': target_column,\n",
        "                'Best Parameters': best_params,\n",
        "                'MSE': mse,\n",
        "                'R²': r2,\n",
        "                'MAE': mae,\n",
        "                'MAPE': mape,\n",
        "                'RMSE': rmse\n",
        "            })\n",
        "\n",
        "            # Forecasting future years\n",
        "            future_data = district_data.iloc[:len(future_years)].copy()\n",
        "            future_data['Year'] = future_years\n",
        "            future_X = future_data.drop(columns=['Year', 'Dist Name'] + [col for col in data.columns if col not in columns], errors='ignore')\n",
        "            future_predictions = best_model.predict(future_X)\n",
        "\n",
        "            # Store forecasted results\n",
        "            for year, prediction in zip(future_years, future_predictions):\n",
        "                results['forecasting'].append({\n",
        "                    'District': district,\n",
        "                    'Year': year,\n",
        "                    'Crop': crop,\n",
        "                    'Target Column': target_column,\n",
        "                    'Forecasted Value': prediction\n",
        "                })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run processing in parallel\n",
        "all_results = Parallel(n_jobs=-1)(delayed(process_district)(district) for district in districts)\n",
        "\n",
        "# Combine results\n",
        "fine_tuning_results = [item for result in all_results for item in result['fine_tuning']]\n",
        "forecasted_results = [item for result in all_results for item in result['forecasting']]\n",
        "\n",
        "# Save fine-tuning metrics to CSV\n",
        "metrics_df = pd.DataFrame(fine_tuning_results)\n",
        "metrics_csv_path = '/content/fine_tuning_results.csv'\n",
        "metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "print(f\"Fine-tuning results saved to {metrics_csv_path}\")\n",
        "\n",
        "# Save forecasted results to CSV\n",
        "forecasted_df = pd.DataFrame(forecasted_results)\n",
        "forecasted_csv_path = '/content/forecasted_future_values.csv'\n",
        "forecasted_df.to_csv(forecasted_csv_path, index=False)\n",
        "print(f\"Forecasted values saved to {forecasted_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyIIlZhIvB6w",
        "outputId": "87902bfa-efeb-4287-867d-715159fed2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning results saved to /content/fine_tuning_results.csv\n",
            "Forecasted values saved to /content/forecasted_future_values.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set seaborn style for plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Iterate over districts and crop target columns to visualize fitting and forecasting\n",
        "for district in districts:\n",
        "    district_data = data[data['Dist Name'] == district]\n",
        "    forecasted_district_data = forecasted_df[forecasted_df['District'] == district]\n",
        "\n",
        "    for crop, columns in crop_columns.items():\n",
        "        for target_column in columns:\n",
        "            # Check if the target column exists in the district data\n",
        "            if target_column not in district_data.columns:\n",
        "                continue\n",
        "\n",
        "            # Prepare the actual data\n",
        "            actual_data = district_data[['Year', target_column]].dropna()\n",
        "\n",
        "            # Prepare the forecasted data\n",
        "            forecasted_data = forecasted_district_data[\n",
        "                forecasted_district_data['Target Column'] == target_column\n",
        "            ]\n",
        "\n",
        "            # Plot the data\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(\n",
        "                actual_data['Year'], actual_data[target_column], label=\"Actual Values\", marker='o'\n",
        "            )\n",
        "            plt.plot(\n",
        "                forecasted_data['Year'], forecasted_data['Forecasted Value'], label=\"Forecasted Values\", linestyle='--', marker='x'\n",
        "            )\n",
        "\n",
        "            # Add title, labels, and legend\n",
        "            plt.title(f\"{district} - {target_column} (Actual vs Forecasted)\", fontsize=14)\n",
        "            plt.xlabel(\"Year\", fontsize=12)\n",
        "            plt.ylabel(target_column, fontsize=12)\n",
        "            plt.legend(loc=\"best\", fontsize=10)\n",
        "            plt.grid(True)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JqUWYKt_FEbj",
        "outputId": "4327f62e-0b40-4db5-d6c2-3b40988f3d8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Major_5_District.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "data = data.drop(columns=['TOTAL AREA (1000 ha)'])  # Adjust as per actual column name\n",
        "\n",
        "# Future years to forecast\n",
        "future_years = list(range(2018, 2026)) + [2030, 2035, 2040, 2045]\n",
        "\n",
        "# Districts to process\n",
        "districts = ['Akola', 'Kolhapur', 'Pune', 'Ratnagiri', 'Wardha']\n",
        "target_columns = data.columns.drop(['Year', 'Dist Name'])  # Exclude non-target columns\n",
        "\n",
        "# Hyperparameter tuning grid\n",
        "param_distributions = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 3],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Function to process each district and target column\n",
        "def process_district(district):\n",
        "    results = {'fine_tuning': [], 'forecasting': []}\n",
        "    district_data = data[data['Dist Name'] == district]\n",
        "\n",
        "    for target_column in target_columns:\n",
        "        # Prepare features (X) and target (y)\n",
        "        X = district_data.drop(columns=['Year', 'Dist Name', target_column], errors='ignore')\n",
        "        y = district_data[target_column]\n",
        "\n",
        "        # Skip columns with insufficient data\n",
        "        if len(y) < 5:\n",
        "            continue\n",
        "\n",
        "        # Train on historical data\n",
        "        X_train = X\n",
        "        y_train = y\n",
        "\n",
        "        # Randomized search for hyperparameter tuning\n",
        "        gbr = GradientBoostingRegressor(random_state=42)\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=gbr,\n",
        "            param_distributions=param_distributions,\n",
        "            n_iter=10,  # Reducing iterations for speed\n",
        "            cv=2,\n",
        "            scoring='neg_mean_squared_error',\n",
        "            n_jobs=-1,\n",
        "            verbose=0\n",
        "        )\n",
        "        random_search.fit(X_train, y_train)\n",
        "\n",
        "        # Best parameters and model\n",
        "        best_params = random_search.best_params_\n",
        "        best_model = random_search.best_estimator_\n",
        "\n",
        "        # Forecasting future years\n",
        "        future_data = district_data.iloc[:len(future_years)].copy()\n",
        "        future_data['Year'] = future_years\n",
        "        future_X = future_data.drop(columns=['Year', 'Dist Name', target_column], errors='ignore')\n",
        "        future_predictions = best_model.predict(future_X)\n",
        "\n",
        "        # Store fine-tuning results\n",
        "        mse = mean_squared_error(y_train, best_model.predict(X_train))\n",
        "        r2 = r2_score(y_train, best_model.predict(X_train))\n",
        "        results['fine_tuning'].append({\n",
        "            'District': district,\n",
        "            'Target Column': target_column,\n",
        "            'Best Parameters': best_params,\n",
        "            'MSE': mse,\n",
        "            'R²': r2\n",
        "        })\n",
        "\n",
        "        # Store forecasted results\n",
        "        for year, prediction in zip(future_years, future_predictions):\n",
        "            results['forecasting'].append({\n",
        "                'District': district,\n",
        "                'Year': year,\n",
        "                'Target Column': target_column,\n",
        "                'Forecasted Value': prediction\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run processing in parallel\n",
        "all_results = Parallel(n_jobs=-1)(delayed(process_district)(district) for district in districts)\n",
        "\n",
        "# Combine results\n",
        "fine_tuning_results = [item for result in all_results for item in result['fine_tuning']]\n",
        "forecasted_results = [item for result in all_results for item in result['forecasting']]\n",
        "\n",
        "# Save fine-tuning metrics to CSV\n",
        "metrics_df = pd.DataFrame(fine_tuning_results)\n",
        "metrics_csv_path = '/content/fine_tuning_results.csv'\n",
        "metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "print(f\"Fine-tuning results saved to {metrics_csv_path}\")\n",
        "\n",
        "# Save forecasted results to CSV\n",
        "forecasted_df = pd.DataFrame(forecasted_results)\n",
        "forecasted_csv_path = '/content/forecasted_future_values.csv'\n",
        "forecasted_df.to_csv(forecasted_csv_path, index=False)\n",
        "print(f\"Forecasted values saved to {forecasted_csv_path}\")\n"
      ],
      "metadata": {
        "id": "Pv3rKk5LpBzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists for aggregate metrics and forecast summaries\n",
        "aggregate_metrics = []\n",
        "forecast_summaries = []\n",
        "\n",
        "# Aggregate fine-tuning results by district\n",
        "for district in metrics_df['District'].unique():\n",
        "    district_metrics = metrics_df[metrics_df['District'] == district]\n",
        "\n",
        "    # Calculate average MSE and R² for the district\n",
        "    avg_mse = district_metrics['MSE'].mean()\n",
        "    avg_r2 = district_metrics['R²'].mean()\n",
        "\n",
        "    # Append aggregate metrics for the district\n",
        "    aggregate_metrics.append({\n",
        "        'District': district,\n",
        "        'Avg MSE': avg_mse,\n",
        "        'Avg R²': avg_r2\n",
        "    })\n",
        "\n",
        "# Aggregate forecasted results by district and year\n",
        "for district in forecasted_df['District'].unique():\n",
        "    district_forecasts = forecasted_df[forecasted_df['District'] == district]\n",
        "\n",
        "    for year in district_forecasts['Year'].unique():\n",
        "        year_forecasts = district_forecasts[district_forecasts['Year'] == year]\n",
        "\n",
        "        # Calculate mean forecasted value for the year\n",
        "        avg_forecast = year_forecasts['Forecasted Value'].mean()\n",
        "\n",
        "        # Append forecast summary for the district and year\n",
        "        forecast_summaries.append({\n",
        "            'District': district,\n",
        "            'Year': year,\n",
        "            'Avg Forecasted Value': avg_forecast\n",
        "        })\n",
        "\n",
        "# Convert aggregate metrics and forecast summaries to DataFrames\n",
        "aggregate_metrics_df = pd.DataFrame(aggregate_metrics)\n",
        "forecast_summary_df = pd.DataFrame(forecast_summaries)\n",
        "\n",
        "# Save aggregated metrics to CSV\n",
        "aggregate_metrics_csv_path = '/content/aggregate_fine_tuning_metrics.csv'\n",
        "aggregate_metrics_df.to_csv(aggregate_metrics_csv_path, index=False)\n",
        "print(f\"Aggregate fine-tuning metrics saved to {aggregate_metrics_csv_path}\")\n",
        "\n",
        "# Save forecast summaries to CSV\n",
        "forecast_summary_csv_path = '/content/forecast_summary.csv'\n",
        "forecast_summary_df.to_csv(forecast_summary_csv_path, index=False)\n",
        "print(f\"Forecast summaries saved to {forecast_summary_csv_path}\")\n",
        "\n",
        "# Display the DataFrames\n",
        "print(\"\\nAggregate Fine-Tuning Metrics:\")\n",
        "print(aggregate_metrics_df)\n",
        "\n",
        "print(\"\\nForecast Summary:\")\n",
        "print(forecast_summary_df)\n"
      ],
      "metadata": {
        "id": "hdVTp6xcpCkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print aggregate metrics for each district\n",
        "aggregate_metrics = []\n",
        "\n",
        "for district in districts:\n",
        "    district_results = [result for result in fine_tuning_results if result['District'] == district]\n",
        "\n",
        "    if district_results:\n",
        "        avg_r2 = np.mean([res['R²'] for res in district_results])\n",
        "        avg_mse = np.mean([res['MSE'] for res in district_results])\n",
        "        count = len(district_results)\n",
        "\n",
        "        aggregate_metrics.append({\n",
        "            'District': district,\n",
        "            'Average R²': avg_r2,\n",
        "            'Average MSE': avg_mse,\n",
        "            'Models Tuned': count\n",
        "        })\n",
        "\n",
        "        print(f\"District: {district}\")\n",
        "        print(f\"  Average R²: {avg_r2:.4f}\")\n",
        "        print(f\"  Average MSE: {avg_mse:.4f}\")\n",
        "        print(f\"  Models Tuned: {count}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "# Convert aggregate metrics to DataFrame for further use if needed\n",
        "aggregate_metrics_df = pd.DataFrame(aggregate_metrics)\n"
      ],
      "metadata": {
        "id": "ZNuEZs2IpE_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set seaborn style for plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Iterate over districts and target columns to visualize fitting and forecasting\n",
        "for district in districts:\n",
        "    district_data = data[data['Dist Name'] == district]\n",
        "    forecasted_district_data = forecasted_df[forecasted_df['District'] == district]\n",
        "\n",
        "    for target_column in target_columns:\n",
        "        # Prepare the actual data\n",
        "        if target_column not in district_data.columns:\n",
        "            continue\n",
        "        actual_data = district_data[['Year', target_column]].dropna()\n",
        "\n",
        "        # Prepare the forecasted data\n",
        "        forecasted_data = forecasted_district_data[forecasted_district_data['Target Column'] == target_column]\n",
        "\n",
        "        # Plot the data\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(\n",
        "            actual_data['Year'], actual_data[target_column], label=\"Actual Values\", marker='o'\n",
        "        )\n",
        "        plt.plot(\n",
        "            forecasted_data['Year'], forecasted_data['Forecasted Value'], label=\"Forecasted Values\", linestyle='--', marker='x'\n",
        "        )\n",
        "\n",
        "        # Add title, labels, and legend\n",
        "        plt.title(f\"{district} - {target_column} (Actual vs Forecasted)\", fontsize=14)\n",
        "        plt.xlabel(\"Year\", fontsize=12)\n",
        "        plt.ylabel(target_column, fontsize=12)\n",
        "        plt.legend(loc=\"best\", fontsize=10)\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "nUO9Z3n3pNY2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}